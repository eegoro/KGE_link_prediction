{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import torch_geometric\n",
    "from torch_geometric import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_temperature = 1\n",
    "regularization = 0\n",
    "test_batch_size = 4\n",
    "learning_rate = 0.0001\n",
    "cpu_num = 10\n",
    "max_steps = 1\n",
    "#save_checkpoint_steps = 10000\n",
    "valid_steps = 10000\n",
    "log_steps = 100\n",
    "test_log_steps = 1000\n",
    "nentity = 0\n",
    "nrelation = 0\n",
    "ntriples_eval_train = 200000\n",
    "neg_size_eval_train = 500\n",
    "model = 'TransE'\n",
    "double_entity_embedding = True # True if RotatE, ComplEx\n",
    "double_relation_embedding = True # True if ComplEx\n",
    "\n",
    "negative_adversarial_sampling = True #In self-adversarial sampling, we do not apply back-propagation on the sampling weight\n",
    "uni_weight = True\n",
    "\n",
    "NEG_SAMPLE_SIZE = 10\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 4\n",
    "VALIDATION_INTERVAL = 10\n",
    "EMBEDDING_SIZE = 10\n",
    "GAMMA = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('clear_data_realbank.csv')\n",
    "df.drop('TRANS_DETAIL', inplace=True, axis=1)\n",
    "df.rename(columns = {'RETAILER' : 'tail', 'CustomerKey' : 'head',\n",
    "                        'MCC' : 'tail_type', 'AMOUNT_EQ' : 'relation'   }, \n",
    "                            inplace = True) \n",
    "# некоторые id магазинов имели разные категории. Здесь id c разл категорией приравниваются к -2 и затем удаляются\n",
    "for i in (range(min(df.tail_type.unique()),max(df.tail_type.unique())+1)):\n",
    "    for j in range(i+1,max(df.tail_type.unique())+1):\n",
    "        for k in (set(df[df.tail_type==i]['tail'].unique())&set(df[df.tail_type==j]['tail'].unique())):\n",
    "            df.loc[df['tail'] == k,'tail_type'] = -2\n",
    "df = df[df.tail_type != -2].reset_index(drop=True)\n",
    "\n",
    "# траты разбиваются на 8 категорий и в дальнейшем будут характеризировать отношения\n",
    "df.relation = pd.qcut(df.relation, q=8, \n",
    "        labels=[\"small\", \"medium_small\", \"medium_small_2\", 'medium_1', 'medium_2', 'medium_large_2', 'medium_large', 'large'])\n",
    "\n",
    "# удаление непопулярных категорий магазинов\n",
    "top_mcc = list(df.tail_type.value_counts()[:10].rename_axis('unique_values').reset_index(name='counts')['unique_values'])\n",
    "df = df[df.tail_type.isin(top_mcc)].reset_index(drop=True)\n",
    "df = df.sort_values('tail_type')\n",
    "\n",
    "# присвоение уникальным id пользователей и магазинов чисел от 0 до len(уникальных id)\n",
    "df['head'] = pd.factorize(df['head'])[0]\n",
    "max_person = max(df['head'])\n",
    "df['tail'] = pd.factorize(df['tail'])[0] + max_person + 1\n",
    "\n",
    "# словарь с типами сущностей и списком их id\n",
    "dict_id = {}\n",
    "dict_id['person'] = list(range(0,max(df['head'])+1))\n",
    "for tail_type in df['tail_type'].unique():\n",
    "    dict_id[tail_type] = list(range(min(df[df.tail_type==tail_type]['tail']),(max(df[df.tail_type==tail_type]['tail'])+1)))\n",
    "\n",
    "# присвоение чисел отношениям\n",
    "dict_rel = {key: idx for idx,key in enumerate(pd.factorize(df.relation)[1].categories)}\n",
    "df['relation'] = df['relation'].apply(lambda x: dict_rel[x])\n",
    "\n",
    "# создание негативных сущностей \n",
    "# neg_head --> tail      neg_tail --> head\n",
    "df['neg_head'] = [random.sample(dict_id['person'],NEG_SAMPLE_SIZE) for _ in range(len(df))]\n",
    "df['neg_tail'] = [random.sample(dict_id[i], NEG_SAMPLE_SIZE) for i in df.tail_type]\n",
    "\n",
    "# разбиение на выборки по времени\n",
    "train = df[(df.tstmp >= '2018-01-01 00:00:00+03:00') & (df.tstmp < '2018-08-01 00:00:00+03:00')]\n",
    "train.drop('tstmp', inplace=True, axis=1, errors='ignore')\n",
    "valid = df[(df.tstmp >= '2018-08-01 00:00:00+03:00') & (df.tstmp < '2018-10-01 00:00:00+03:00')]\n",
    "valid.drop('tstmp', inplace=True, axis=1, errors='ignore')\n",
    "test = df[(df.tstmp >= '2018-10-01 00:00:00+03:00') & (df.tstmp < '2019-01-01 00:00:00+03:00')]\n",
    "test.drop('tstmp', inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 58%\n",
      "VALID: 17%\n",
      "TEST: 25%\n"
     ]
    }
   ],
   "source": [
    "print(f'TRAIN: {round(len(train)/len(df)*100)}%')\n",
    "print(f'VALID: {round(len(valid)/len(df)*100)}%')\n",
    "print(f'TEST: {round(len(test)/len(df)*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1795880/1795880 [00:50<00:00, 35735.01it/s]\n",
      "c:\\Users\\Elena\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_count, train_true_head, train_true_tail = defaultdict(lambda: 4), defaultdict(list), defaultdict(list)\n",
    "for i in tqdm(train.index):\n",
    "    head, relation, tail = train.loc[i,'head'], train.loc[i,'relation'],  train.loc[i,'tail']\n",
    "    train_count[(head, relation)] += 1\n",
    "    train_count[(tail, -relation-1)] += 1\n",
    "    train_true_head[(relation, tail)].append(head)\n",
    "    train_true_tail[(head, relation)].append(tail)\n",
    "\n",
    "train['subsampling_weight'] = [(1/(train_count[(train.loc[i,'head'], train.loc[i,'relation'])] \n",
    "                                + train_count[(train.loc[i,'tail'], -train.loc[i,'relation']-1)]))**(1/2)\n",
    "                                                                                for i in train.index]\n",
    "\n",
    "nentity = len(df['tail'].unique())+len(df['head'].unique())\n",
    "nrelation = len(df['relation'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGEModel(nn.Module):\n",
    "    def __init__(self, nentity, nrelation, embedding_size, gamma, evaluator,\n",
    "                 double_entity_embedding=False, double_relation_embedding=False, epsilon = 2.0):\n",
    "        super(KGEModel, self).__init__()\n",
    "        \n",
    "        self.gamma = nn.Parameter(\n",
    "            torch.Tensor([gamma]), \n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        self.embedding_range = nn.Parameter(\n",
    "            torch.Tensor([(self.gamma.item() + epsilon) / embedding_size]), \n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        self.entity_dim = embedding_size*2 if double_entity_embedding else embedding_size\n",
    "        self.relation_dim = embedding_size*2 if double_relation_embedding else embedding_size\n",
    "        \n",
    "        self.entity_embedding = nn.Parameter(torch.zeros(nentity, self.entity_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.entity_embedding, \n",
    "            a=-self.embedding_range.item(), \n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "        \n",
    "        self.relation_embedding = nn.Parameter(torch.zeros(nrelation, self.relation_dim))\n",
    "        nn.init.uniform_(\n",
    "            tensor=self.relation_embedding, \n",
    "            a=-self.embedding_range.item(), \n",
    "            b=self.embedding_range.item()\n",
    "        )\n",
    "\n",
    "        self.evaluator = evaluator\n",
    "        \n",
    "    def forward(self, head, tail, relation, neg_head, neg_tail):\n",
    "        head_E = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=head\n",
    "            ).unsqueeze(1)\n",
    "        \n",
    "        relation_E = torch.index_select(\n",
    "                self.relation_embedding, \n",
    "                dim=0, \n",
    "                index=relation\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "        tail_E = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=tail\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "        neg_head_E = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=neg_head.view(-1)\n",
    "            ).view(neg_head.size(0), neg_head.size(1), -1)  #batch_size, negative_sample_size\n",
    "            \n",
    "        neg_tail_E  = torch.index_select(\n",
    "                self.entity_embedding, \n",
    "                dim=0, \n",
    "                index=neg_tail.view(-1)\n",
    "            ).view(neg_tail.size(0), neg_tail.size(1), -1) \n",
    "            \n",
    "        #TransE\n",
    "        positive_score = (head_E + relation_E) - tail_E\n",
    "        negative_tail_score = (head_E + relation_E) - neg_tail_E\n",
    "        negative_head_score = neg_head_E + (relation_E - tail_E)\n",
    "\n",
    "        positive_score = self.gamma.item() - torch.norm(positive_score, p=1, dim=2)\n",
    "        negative_tail_score = self.gamma.item() - torch.norm(negative_tail_score, p=1, dim=2)\n",
    "        negative_head_score = self.gamma.item() - torch.norm(negative_head_score, p=1, dim=2)\n",
    "        \n",
    "        return positive_score, negative_tail_score, negative_head_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def eval(self, input_dict):\n",
    "        y_pred_pos, y_pred_neg = input_dict['y_pred_pos'], input_dict['y_pred_neg']\n",
    "        y_pred = torch.cat([y_pred_pos.view(-1,1), y_pred_neg], dim = 1)\n",
    "        argsort = torch.argsort(y_pred, dim = 1, descending = True)\n",
    "        ranking_list = torch.nonzero(argsort == 0, as_tuple=False)\n",
    "        ranking_list = ranking_list[:, 1] + 1\n",
    "        hits1_list = (ranking_list <= 1).to(torch.float)\n",
    "        hits3_list = (ranking_list <= 3).to(torch.float)\n",
    "        hits10_list = (ranking_list <= 10).to(torch.float)\n",
    "        mrr_list = 1./ranking_list.to(torch.float)\n",
    "\n",
    "        return {'hits@1_list': hits1_list,\n",
    "                     'hits@3_list': hits3_list,\n",
    "                     'hits@10_list': hits10_list,\n",
    "                     'mrr_list': mrr_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp = train[:100]\n",
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "kge_model = KGEModel(\n",
    "        nentity=nentity,\n",
    "        nrelation=nrelation,\n",
    "        embedding_size=EMBEDDING_SIZE,\n",
    "        gamma=GAMMA,\n",
    "        double_entity_embedding=double_entity_embedding,\n",
    "        double_relation_embedding=double_relation_embedding,\n",
    "        evaluator=evaluator\n",
    "    )\n",
    "kge_model = kge_model.cuda()\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()), \n",
    "            lr=learning_rate\n",
    "        )\n",
    "\n",
    "log = {}\n",
    "for num_epoch in tqdm(range(EPOCH)):\n",
    "    train_iter = chunks(train_exp, BATCH_SIZE)\n",
    "    iteration = math.ceil(len(train_exp)/BATCH_SIZE) \n",
    "    for i in range(iteration):\n",
    "        kge_model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_batch = next(train_iter)\n",
    "\n",
    "        head = torch.tensor(np.array(train_batch['head'])).cuda()\n",
    "        tail = torch.tensor(np.array(train_batch['tail'])).cuda()\n",
    "        relation = torch.tensor(np.array(train_batch['relation'])).cuda()\n",
    "        neg_head = torch.tensor(np.array(list(train_batch['neg_head']))).cuda()\n",
    "        neg_tail = torch.tensor(np.array(list(train_batch['neg_tail']))).cuda()\n",
    "        subsampling_weight = torch.tensor(np.array(train_batch['subsampling_weight'])).cuda()\n",
    "\n",
    "        positive_score, negative_tail_score, negative_head_score = kge_model(head, tail, relation, neg_head, neg_tail)\n",
    "\n",
    "        positive_score = F.logsigmoid(positive_score).squeeze(dim = 1)\n",
    "        if negative_adversarial_sampling:\n",
    "            #In self-adversarial sampling, we do not apply back-propagation on the sampling weight\n",
    "            negative_tail_score = (F.softmax(negative_tail_score * adversarial_temperature, dim = 1).detach() \n",
    "                              * F.logsigmoid(-negative_tail_score)).sum(dim = 1)\n",
    "            negative_head_score = (F.softmax(negative_head_score * adversarial_temperature, dim = 1).detach() \n",
    "                              * F.logsigmoid(-negative_head_score)).sum(dim = 1)\n",
    "        else:\n",
    "            negative_tail_score = F.logsigmoid(-negative_tail_score).mean(dim = 1)\n",
    "            negative_head_score = F.logsigmoid(-negative_head_score).mean(dim = 1)\n",
    "\n",
    "        if uni_weight:\n",
    "            positive_sample_loss = - positive_score.mean()\n",
    "            negative_sample_tail_loss = - negative_tail_score.mean()\n",
    "            negative_sample_head_loss = - negative_head_score.mean()\n",
    "        else:\n",
    "            positive_sample_loss = - (subsampling_weight * positive_score).sum()/subsampling_weight.sum()\n",
    "            negative_sample_tail_loss = - (subsampling_weight * negative_tail_score).sum()/subsampling_weight.sum()\n",
    "            negative_sample_head_loss = - (subsampling_weight * negative_head_score).sum()/subsampling_weight.sum()\n",
    "\n",
    "        loss = (2*positive_sample_loss + negative_sample_tail_loss+negative_sample_head_loss)/4\n",
    "\n",
    "        if regularization != 0.0:\n",
    "            #Use L3 regularization for ComplEx and DistMult\n",
    "            regularization = regularization * (\n",
    "                kge_model.entity_embedding.norm(p = 3)**3 + \n",
    "                kge_model.relation_embedding.norm(p = 3).norm(p = 3)**3\n",
    "            )\n",
    "            loss = loss + regularization\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (num_epoch+1)//VALIDATION_INTERVAL == 0:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    695,       1, 2155224],\n",
       "        [   3340,       1, 1255182],\n",
       "        [   3468,       6,  936329],\n",
       "        [   1758,       1,  467378]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2218828, 2304479, 2250254, 1846286, 1935662, 2151055, 2283020, 1977150,\n",
       "         1825154, 2193574],\n",
       "        [ 206160, 1580145, 1194749, 1480901, 1518416, 1333486,  300682, 1797609,\n",
       "         1438722,  919222],\n",
       "        [ 490480,  824455,  508149,  444770, 1686218,  881021,  170813, 1361398,\n",
       "          363282,  670189],\n",
       "        [1762836,  551054,  400965, 1467674,  275619, 1334130,  633564,  215826,\n",
       "         1257242,  170830]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1147, 0.1336, 0.0851, 0.0909])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampling_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "positive_sample = torch.tensor([])\n",
    "positive_sample = torch.cat((positive_sample, torch.LongTensor([0,1,2])),-1)\n",
    "positive_sample = torch.cat((positive_sample, torch.LongTensor([0,1,2])),-1)\n",
    "print(positive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "positive_sample = []\n",
    "positive_sample.append([0,1,2])\n",
    "positive_sample.append([0,1,2])\n",
    "print(torch.LongTensor(positive_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count[(head, relation, head_type)] + train_count[(tail, -relation-1, tail_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1386750490563073"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/(train_count[(head, relation, head_type)] + train_count[(tail, -relation-1, tail_type)]))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045 162173 10\n"
     ]
    }
   ],
   "source": [
    "print(entity_dict[tail_type][0], entity_dict[tail_type][1], negative_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34857, 102533, 67879, 151864, 101192, 48360, 63725, 54264, 107219, 157469]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(range(entity_dict[tail_type][0], entity_dict[tail_type][1]), negative_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 157851,   47495,   77106,   55592,  134623,  125030,   95340,  141292,\n",
       "          89379,    7282,  599768,  675371,  802333,  719380,  929603, 1023578,\n",
       "        1596766,  449713, 1185347, 1295857,  468832, 1229757,  312410,  645505,\n",
       "        1542261, 1004376,  939976, 1681983, 1246682,  547799,  540114,  730751,\n",
       "        1562784,  955217, 1149887, 1438719, 1130914,  963494,  699750, 1497028],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sample.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       0,    4045],\n",
       "        [   1505,       0, 1377759],\n",
       "        [   2172,       0, 1377762],\n",
       "        [   3567,       0, 1377775]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       0,    4045],\n",
       "        [   1505,       0, 1377759],\n",
       "        [   2172,       0, 1377762],\n",
       "        [   3567,       0, 1377775]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2963,       2,  435157],\n",
      "        [   2831,       2, 2327754],\n",
      "        [   3708,       2, 2327753],\n",
      "        [    173,       2,   10857]])\n",
      "tensor([[1549108,  291924,  358954,  234002,  718396,  271483,  361656, 1540361,\n",
      "         1097434,  743985],\n",
      "        [2335794, 2237600, 2333249, 2004466, 2288563, 1956566, 2158608, 1837253,\n",
      "         2247794, 2219773],\n",
      "        [1844113, 2072521, 1967319, 1954988, 1832988, 2106742, 1981877, 1915342,\n",
      "         1927755, 2172085],\n",
      "        [  36823,   53804,  105826,   85847,  143019,  151635,  138683,  157103,\n",
      "           19976,   83402]])\n",
      "tensor([0.1091, 0.1348, 0.1125, 0.1387])\n"
     ]
    }
   ],
   "source": [
    "print(positive_sample)\n",
    "print(negative_sample)\n",
    "print(subsampling_weight)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55ef9a55fdc765f2ef7428dcd7a5e17e687a3fb5472cc7aae07b9f2f89984f80"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
