{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_SAMPLE_SIZE = 10\n",
    "info = {'NEG_SAMPLE_SIZE': NEG_SAMPLE_SIZE}\n",
    "\n",
    "if not (os.path.exists('data')):\n",
    "    os.mkdir('data')\n",
    "with open('data//info.txt', 'w') as info_file:\n",
    "            json.dump(info, info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv ('clear_data_realbank.csv')\n",
    "df.drop('TRANS_DETAIL', inplace=True, axis=1)\n",
    "df.rename(columns = {'RETAILER' : 'tail', 'CustomerKey' : 'head',\n",
    "                        'MCC' : 'tail_type', 'AMOUNT_EQ' : 'relation'   }, \n",
    "                            inplace = True) \n",
    "# некоторые id магазинов имели разные категории. Здесь id c разл категорией приравниваются к -2 и затем удаляются\n",
    "for i in (range(min(df.tail_type.unique()),max(df.tail_type.unique())+1)):\n",
    "    for j in range(i+1,max(df.tail_type.unique())+1):\n",
    "        for k in (set(df[df.tail_type==i]['tail'].unique())&set(df[df.tail_type==j]['tail'].unique())):\n",
    "            df.loc[df['tail'] == k,'tail_type'] = -2\n",
    "df = df[df.tail_type != -2].reset_index(drop=True)\n",
    "\n",
    "# траты разбиваются на 8 категорий и в дальнейшем будут характеризировать отношения\n",
    "df.relation = pd.qcut(df.relation, q=8, \n",
    "        labels=[\"small\", \"medium_small\", \"medium_small_2\", 'medium_1', 'medium_2', 'medium_large_2', 'medium_large', 'large'])\n",
    "\n",
    "# удаление непопулярных категорий магазинов\n",
    "top_mcc = list(df.tail_type.value_counts()[:10].rename_axis('unique_values').reset_index(name='counts')['unique_values'])\n",
    "df = df[df.tail_type.isin(top_mcc)].reset_index(drop=True)\n",
    "df = df.sort_values('tail_type')\n",
    "\n",
    "# присвоение уникальным id пользователей и магазинов чисел от 0 до len(уникальных id)\n",
    "df['head'] = pd.factorize(df['head'])[0]\n",
    "max_person = max(df['head'])\n",
    "df['tail'] = pd.factorize(df['tail'])[0] + max_person + 1\n",
    "\n",
    "# словарь с типами сущностей и списком их id\n",
    "dict_id = {}\n",
    "dict_id['person'] = list(range(0,max(df['head'])+1))\n",
    "for tail_type in df['tail_type'].unique():\n",
    "    dict_id[tail_type] = list(range(min(df[df.tail_type==tail_type]['tail']),(max(df[df.tail_type==tail_type]['tail'])+1)))\n",
    "\n",
    "# присвоение чисел отношениям\n",
    "dict_rel = {key: idx for idx,key in enumerate(pd.factorize(df.relation)[1].categories)}\n",
    "df['relation'] = df['relation'].apply(lambda x: dict_rel[x])\n",
    "\n",
    "# создание негативных сущностей \n",
    "# neg_head --> tail      neg_tail --> head\n",
    "df['neg_head'] = [random.sample(dict_id['person'],NEG_SAMPLE_SIZE) for _ in range(len(df))]\n",
    "df['neg_tail'] = [random.sample(dict_id[i], NEG_SAMPLE_SIZE) for i in df.tail_type]\n",
    "\n",
    "# разбиение на выборки по времени\n",
    "train = df[(df.tstmp >= '2018-01-01 00:00:00+03:00') & (df.tstmp < '2018-08-01 00:00:00+03:00')]\n",
    "train.drop('tstmp', inplace=True, axis=1, errors='ignore')\n",
    "valid = df[(df.tstmp >= '2018-08-01 00:00:00+03:00') & (df.tstmp < '2018-10-01 00:00:00+03:00')]\n",
    "valid.drop('tstmp', inplace=True, axis=1, errors='ignore')\n",
    "test = df[(df.tstmp >= '2018-10-01 00:00:00+03:00') & (df.tstmp < '2019-01-01 00:00:00+03:00')]\n",
    "test.drop('tstmp', inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1795880/1795880 [00:37<00:00, 48407.10it/s]\n",
      "/var/folders/ft/5vplhl0d36b0qq16wf5p_mbh0000gn/T/ipykernel_1770/1718052353.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['subsampling_weight'] = [(1/(train_count[(train.loc[i,'head'], train.loc[i,'relation'])]\n"
     ]
    }
   ],
   "source": [
    "train_count, train_true_head, train_true_tail = defaultdict(lambda: 4), defaultdict(list), defaultdict(list)\n",
    "for i in tqdm(train.index):\n",
    "    head, relation, tail = train.loc[i,'head'], train.loc[i,'relation'],  train.loc[i,'tail']\n",
    "    train_count[(head, relation)] += 1\n",
    "    train_count[(tail, -relation-1)] += 1\n",
    "    train_true_head[(relation, tail)].append(head)\n",
    "    train_true_tail[(head, relation)].append(tail)\n",
    "\n",
    "train['subsampling_weight'] = [(1/(train_count[(train.loc[i,'head'], train.loc[i,'relation'])] \n",
    "                                + train_count[(train.loc[i,'tail'], -train.loc[i,'relation']-1)]))**(1/2)\n",
    "                                                                                for i in train.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r'data/train.csv', index=False)\n",
    "valid.to_csv(r'data/train.csv', index=False)\n",
    "test.to_csv(r'data/train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55ef9a55fdc765f2ef7428dcd7a5e17e687a3fb5472cc7aae07b9f2f89984f80"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
